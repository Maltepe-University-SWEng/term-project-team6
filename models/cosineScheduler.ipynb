{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNpfu+cu6OtHres9NPJHZsO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5e87ed7cea494317a349d46262321cb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4df92e12efab452b8a9903b037a152c0","IPY_MODEL_436d0dcb2ea1441e90ff53ee486a722e","IPY_MODEL_34b7fa1755bb4bada13e877649030a19"],"layout":"IPY_MODEL_7d2ad7257c1f40cdb32b93b2a9d37c22"}},"4df92e12efab452b8a9903b037a152c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93e345546ebc48c4ba35b61bfb921532","placeholder":"​","style":"IPY_MODEL_01e7c303ddad4461934d8e23085771fc","value":"Map: 100%"}},"436d0dcb2ea1441e90ff53ee486a722e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5b9d10ffe94d37b98e9fd46a62843e","max":1207,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c7b2671294b4d029dbef5891869b39d","value":1207}},"34b7fa1755bb4bada13e877649030a19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45a920a0b0244767a8ba134cc47e01ee","placeholder":"​","style":"IPY_MODEL_32f8e3f13c284cdc9a9ff729082648f0","value":" 1207/1207 [00:02&lt;00:00, 519.00 examples/s]"}},"7d2ad7257c1f40cdb32b93b2a9d37c22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93e345546ebc48c4ba35b61bfb921532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e7c303ddad4461934d8e23085771fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a5b9d10ffe94d37b98e9fd46a62843e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c7b2671294b4d029dbef5891869b39d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45a920a0b0244767a8ba134cc47e01ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32f8e3f13c284cdc9a9ff729082648f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tm6SRcQ2nVSJ","executionInfo":{"status":"ok","timestamp":1746985459396,"user_tz":-180,"elapsed":7581,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}},"outputId":"7ce795f8-2cfd-43d1-9eec-1b8ad453a049"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Collecting datasets\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}],"source":["!pip install transformers datasets"]},{"cell_type":"code","source":["import re\n","import json\n","from datasets import Dataset\n","\n","def noktalama_kaldir(metin):\n","    # Yaygın noktalama işaretlerini kaldır\n","    metin = re.sub(r'[^\\w\\s]', '', metin)\n","    return metin\n","\n","# Verisetinizin bulunduğu yolu belirtin\n","veri_yolu = '/content/fikralarFinal.json' # Verisetinizin dosya adı ve uzantısını doğru belirtin\n","\n","with open(veri_yolu, 'r', encoding='utf-8') as f:\n","    veri = json.load(f)\n","\n","temizlenmis_fikralar = []\n","for kayit in veri:\n","    if \"icerik\" in kayit:\n","        temizlenmis_fikralar.append(noktalama_kaldir(kayit[\"icerik\"]))\n","\n","temizlenmis_dataset = Dataset.from_dict({\"text\": temizlenmis_fikralar})\n","\n","print(f\"Toplam temizlenmiş fıkra sayısı: {len(temizlenmis_fikralar)}\")\n","print(\"İlk birkaç temizlenmiş fıkra:\", temizlenmis_dataset[:5])\n","\n","# Sonraki adımlarda bu 'temizlenmis_dataset'i kullanabilirsiniz."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zb9X1GYvnXCc","executionInfo":{"status":"ok","timestamp":1746988637589,"user_tz":-180,"elapsed":43,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}},"outputId":"aa714104-6a98-4ad9-eb0d-6224c25029b6"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Toplam temizlenmiş fıkra sayısı: 1207\n","İlk birkaç temizlenmiş fıkra: {'text': ['Fıkra Metni', 'Nasreddin Hoca ya dert yaniyorlar Yahu Hoca senin kari çok geziyor Hoca  Olur mu canim O kadar gezse arada bir bizim eve de ugrar', 'Iki deli havuzun basinda oturuyorlarmisBiri kalkip havuza seker atmisHavuzdan bir yudum almis ve tükürmüsArkadasina Havuza seker attim ama tatli olmadi Arkadasi Karistirmadinki salak', 'Iki deli birgün deliler hastanesinden kaçmislarKimse bu delileri bulamamislarDoktorlar ümitlerini kestikleri an deliler çika gelmisDoktorlar hayretle niye geldiniz demis DelilerYarin kaçacagizda onun provasini yaptik', 'Delinin biri yolun kenarindaki uçurumda durmus asagiya bakarak 13 13 13 diye soyleniyormus Oradan gecen biri delinin ne yaptigini merak etmis yanasarak  ne yapi diyemeden deli onu birden uçurumdan asagiya ativermis ve devam etmis 14 14 14']}\n"]}]},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","model_adi = \"ytu-ce-cosmos/turkish-gpt2\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_adi)\n","model = GPT2LMHeadModel.from_pretrained(model_adi)\n","\n","# Özel bir <|endoftext|> tokeni ekleyebiliriz (isteğe bağlı)\n","tokenizer.pad_token = tokenizer.eos_token\n","model.config.pad_token_id = model.config.eos_token_id"],"metadata":{"id":"2nlBDLkXoG9g","executionInfo":{"status":"ok","timestamp":1746988668937,"user_tz":-180,"elapsed":904,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def tokenize_function(example):\n","    return tokenizer(example[\"text\"], truncation=True)\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["5e87ed7cea494317a349d46262321cb3","4df92e12efab452b8a9903b037a152c0","436d0dcb2ea1441e90ff53ee486a722e","34b7fa1755bb4bada13e877649030a19","7d2ad7257c1f40cdb32b93b2a9d37c22","93e345546ebc48c4ba35b61bfb921532","01e7c303ddad4461934d8e23085771fc","4a5b9d10ffe94d37b98e9fd46a62843e","3c7b2671294b4d029dbef5891869b39d","45a920a0b0244767a8ba134cc47e01ee","32f8e3f13c284cdc9a9ff729082648f0"]},"id":"zezFa5Bjo6HF","executionInfo":{"status":"ok","timestamp":1746988678009,"user_tz":-180,"elapsed":3782,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}},"outputId":"abcf5375-bdcc-4972-8975-1e2b0571206c"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1207 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e87ed7cea494317a349d46262321cb3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}]},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=False # mlm=False (Masked Language Modeling) yerine sadece Language Modeling yapıyoruz\n",")"],"metadata":{"id":"Po6XVOROpaNg","executionInfo":{"status":"ok","timestamp":1746988681190,"user_tz":-180,"elapsed":10,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","\n","output_model_adi = \"gpt2-fikra-uretici\"\n","output_dir = f\"./{output_model_adi}\"\n","\n","training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    overwrite_output_dir=True,\n","    num_train_epochs=6,\n","    per_device_train_batch_size=4,\n","    save_steps=100,\n","    save_total_limit=2,\n","    learning_rate=5e-5,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    lr_scheduler_type= 'cosine',\n","    push_to_hub=False,\n",")\n"],"metadata":{"id":"GocZ5aVnpw3W","executionInfo":{"status":"ok","timestamp":1746989481125,"user_tz":-180,"elapsed":50,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()\n","\n","trainer.save_model(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"metadata":{"id":"3JRXjQhdyfhm","executionInfo":{"status":"ok","timestamp":1746990579729,"user_tz":-180,"elapsed":1097208,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}},"colab":{"base_uri":"https://localhost:8080/","height":259},"outputId":"936940ab-5611-44da-a958-f47310f046c2"},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1812' max='1812' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1812/1812 18:13, Epoch 6/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.641400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.555400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.538300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('./gpt2-fikra-uretici/tokenizer_config.json',\n"," './gpt2-fikra-uretici/special_tokens_map.json',\n"," './gpt2-fikra-uretici/vocab.json',\n"," './gpt2-fikra-uretici/merges.txt',\n"," './gpt2-fikra-uretici/added_tokens.json')"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["def fikra_uret(prompt, max_length=50, num_return_sequences=1, temperature=0.5, prefix=\"\"):\n","    cikti = fikra_uretici(prefix + prompt,\n","                        max_length=max_length,\n","                        num_return_sequences=num_return_sequences,\n","                        temperature=temperature,\n","                        do_sample=True,\n","                        top_k=50,\n","                        top_p=0.95)\n","    for i, sonuc in enumerate(cikti):\n","        print(f\"Üretilen Fıkra {i+1}: {sonuc['generated_text']}\")\n","\n","# Örnek fıkra üretimi\n","baslangic = \"Keloğlan\"\n","fikra_uret(baslangic)\n","\n","#baslangic2 = \"Temel ile Dursun bir gün:\"\n","fikra_uret(baslangic2, max_length=50, temperature=0.6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PYup3ezfq-0","executionInfo":{"status":"ok","timestamp":1746990627886,"user_tz":-180,"elapsed":961,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}},"outputId":"de1d11a8-6c5c-47d7-f376-2f528beab0ad"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Üretilen Fıkra 1: Keloğlan bir gün bir dükkana gitmiş:-Bana bir ekmek verin.-Dükkan sahibi:-Kaç para var?-Keloğlan:-Hiç yok ama ekmeğin kokusunu alırım!; demiş;-Öyleyse neden ekmeğin kokusunu almayasın?;;-Çünkü\n","Üretilen Fıkra 1: Temel ile Dursun bir gün: - Uşağum oruçlu oruçlu kaç hamsi yiyepilursun? - 100 tane demiş. - Hadi oradan yesen yesen 1 tane yersin geriye kalan 99 hamsiyi oruçsuz yersin demiş\n"]}]},{"cell_type":"code","source":["import os\n","print(os.listdir('./'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Em4Q5qzdfrTr","executionInfo":{"status":"ok","timestamp":1746991003576,"user_tz":-180,"elapsed":7,"user":{"displayName":"Eren Altin","userId":"00593478860408640384"}},"outputId":"5dad1f8c-3295-4abb-a137-d941b1fcd866"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["['.config', 'wandb', 'drive', 'fikralarFinal.json', 'gpt2-fikra-uretici', 'sample_data']\n"]}]},{"cell_type":"code","source":["!zip -r gpt2-fikra-model.zip ./gpt2-fikra-uretici\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTy0pLWXyyC7","outputId":"130f5073-b179-433c-c30c-6cc47fdd5070"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: gpt2-fikra-uretici/ (stored 0%)\n","  adding: gpt2-fikra-uretici/config.json (deflated 52%)\n","  adding: gpt2-fikra-uretici/generation_config.json (deflated 31%)\n","  adding: gpt2-fikra-uretici/runs/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-00-26_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-00-26_0282afadad7d/events.out.tfevents.1746986429.0282afadad7d.397.2 (deflated 62%)\n","  adding: gpt2-fikra-uretici/runs/May11_17-48-41_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_17-48-41_0282afadad7d/events.out.tfevents.1746985739.0282afadad7d.397.0 (deflated 60%)\n","  adding: gpt2-fikra-uretici/runs/May11_17-48-41_0282afadad7d/events.out.tfevents.1746986252.0282afadad7d.397.1 (deflated 62%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-51-21_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-51-21_0282afadad7d/events.out.tfevents.1746989483.0282afadad7d.397.8 (deflated 60%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-38-11_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-38-11_0282afadad7d/events.out.tfevents.1746988696.0282afadad7d.397.6 (deflated 60%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-00-55_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-00-55_0282afadad7d/events.out.tfevents.1746986457.0282afadad7d.397.3 (deflated 62%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-13-04_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-13-04_0282afadad7d/events.out.tfevents.1746987206.0282afadad7d.397.5 (deflated 60%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-45-22_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-45-22_0282afadad7d/events.out.tfevents.1746989124.0282afadad7d.397.7 (deflated 60%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-01-05_0282afadad7d/ (stored 0%)\n","  adding: gpt2-fikra-uretici/runs/May11_18-01-05_0282afadad7d/events.out.tfevents.1746986466.0282afadad7d.397.4 (deflated 60%)\n","  adding: gpt2-fikra-uretici/model.safetensors (deflated 7%)\n","  adding: gpt2-fikra-uretici/training_args.bin (deflated 51%)\n","  adding: gpt2-fikra-uretici/merges.txt (deflated 60%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/ (stored 0%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/config.json (deflated 52%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/generation_config.json (deflated 31%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/rng_state.pth (deflated 25%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/model.safetensors (deflated 7%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/training_args.bin (deflated 51%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/merges.txt (deflated 60%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/optimizer.pt (deflated 8%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/trainer_state.json (deflated 58%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/special_tokens_map.json (deflated 74%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/vocab.json (deflated 71%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/scheduler.pt (deflated 56%)\n","  adding: gpt2-fikra-uretici/checkpoint-1812/tokenizer_config.json (deflated 56%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/ (stored 0%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/config.json (deflated 52%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/generation_config.json (deflated 31%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/rng_state.pth (deflated 25%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/model.safetensors (deflated 7%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/training_args.bin (deflated 51%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/merges.txt (deflated 60%)\n","  adding: gpt2-fikra-uretici/checkpoint-1800/optimizer.pt"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"gpt2-fikra-model.zip\")\n"],"metadata":{"id":"YNC7vHCqyyvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G0Rjv2H-y1A_"},"execution_count":null,"outputs":[]}]}